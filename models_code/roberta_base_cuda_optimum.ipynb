{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from optimum.bettertransformer import BetterTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1\n",
      "Is CUDA enabled? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (C:/Users/Gusso/.cache/huggingface/datasets/financial_phrasebank/sentences_50agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-4069f8bdc2072a81.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-255302c37e6b94c9.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-913aca77f5bc0114.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 604\n",
      "})\n",
      "Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 1208\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"financial_phrasebank\", 'sentences_50agree')\n",
    "\n",
    "neutrals = dataset.filter(lambda example: example[\"label\"] == 1)\n",
    "positives = dataset.filter(lambda example: example[\"label\"] == 2)\n",
    "negatives = dataset.filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "short_positives = positives['train'].select(range(len(negatives['train'])))\n",
    "\n",
    "print(short_positives)\n",
    "\n",
    "downsized_dataset = concatenate_datasets([short_positives, negatives['train']])\n",
    "\n",
    "print(downsized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-9ab259d81c7af6d1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 1087\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 121\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def replace_values(example):\n",
    "    # Replace values in the label column\n",
    "    if \"label\" in example:\n",
    "        example[\"label\"] = 1 if example[\"label\"] == 2 else example[\"label\"]\n",
    "    return example\n",
    "\n",
    "# Use the map function to apply the custom mapping\n",
    "downsized_dataset = downsized_dataset.map(replace_values)\n",
    "downsized_dataset = downsized_dataset.train_test_split(test_size=0.1, shuffle=True)\n",
    "print(downsized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_datasets = downsized_dataset['train'].map(tokenize_function, batched=True)\n",
    "tokenized_datasets_eval = downsized_dataset['test'].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498596904\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\")\n",
    "\n",
    "model = model.to(0)\n",
    "\n",
    "print(model.get_memory_footprint())\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", per_device_train_batch_size=4, per_device_eval_batch_size=4, gradient_accumulation_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 34/102 [00:43<01:19,  1.17s/it]\n",
      " 33%|███▎      | 34/102 [00:45<01:19,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3460485339164734, 'eval_accuracy': 0.9008264462809917, 'eval_runtime': 1.8715, 'eval_samples_per_second': 64.654, 'eval_steps_per_second': 16.564, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 68/102 [01:26<00:39,  1.18s/it]\n",
      " 67%|██████▋   | 68/102 [01:28<00:39,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18661323189735413, 'eval_accuracy': 0.9504132231404959, 'eval_runtime': 1.956, 'eval_samples_per_second': 61.861, 'eval_steps_per_second': 15.849, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [02:11<00:00,  1.18s/it]\n",
      "100%|██████████| 102/102 [02:13<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04625728353857994, 'eval_accuracy': 0.9917355371900827, 'eval_runtime': 2.0555, 'eval_samples_per_second': 58.866, 'eval_steps_per_second': 15.081, 'epoch': 3.0}\n",
      "{'train_runtime': 133.1379, 'train_samples_per_second': 24.493, 'train_steps_per_second': 0.766, 'train_loss': 0.2052622215420592, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=102, training_loss=0.2052622215420592, metrics={'train_runtime': 133.1379, 'train_samples_per_second': 24.493, 'train_steps_per_second': 0.766, 'train_loss': 0.2052622215420592, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "model = BetterTransformer.transform(model)\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Gusso/.cache/huggingface/datasets/zeroshot___csv/zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 2/2 [00:00<00:00, 888.15it/s]\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b2d98c45395bc49c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-98a6e9e55fa382e5.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e8c909d346827c2d.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0978fe6a29e3fa06.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 4846\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = load_dataset('zeroshot/twitter-financial-news-sentiment')\n",
    "\n",
    "def filter_function(example):\n",
    "    return example[\"label\"] != 2\n",
    "\n",
    "# Use the filter method to remove records\n",
    "filtered_dataset = validation_dataset.filter(filter_function)\n",
    "\n",
    "def tokenize_function2(examples):\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_datasets_validation = filtered_dataset.map(tokenize_function2, batched=True)\n",
    "\n",
    "# Print the modified dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:04<00:00, 47.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7557470202445984,\n",
       " 'eval_accuracy': 0.8467153284671532,\n",
       " 'eval_runtime': 4.403,\n",
       " 'eval_samples_per_second': 186.691,\n",
       " 'eval_steps_per_second': 46.786}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate(eval_dataset=tokenized_datasets_validation['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging_torch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

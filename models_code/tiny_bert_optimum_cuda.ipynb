{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from optimum.bettertransformer import BetterTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1\n",
      "Is CUDA enabled? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (C:/Users/Gusso/.cache/huggingface/datasets/financial_phrasebank/sentences_50agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.94it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"financial_phrasebank\", 'sentences_50agree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of negatives 604\n",
      "number of neutral 2879\n",
      "number of positives 1363\n"
     ]
    }
   ],
   "source": [
    "value_count_0=dataset['train']['label'].count(0)\n",
    "value_count_1=dataset['train']['label'].count(1)\n",
    "value_count_2=dataset['train']['label'].count(2)\n",
    "\n",
    "\n",
    "print('number of negatives',value_count_0)\n",
    "print('number of neutral',value_count_1)\n",
    "print('number of positives',value_count_2)\n",
    "#count_1=value_count['1'] # if it is str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-4069f8bdc2072a81.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-255302c37e6b94c9.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-913aca77f5bc0114.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 604\n",
      "})\n",
      "Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 1208\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neutrals = dataset.filter(lambda example: example[\"label\"] == 1)\n",
    "positives = dataset.filter(lambda example: example[\"label\"] == 2)\n",
    "negatives = dataset.filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "short_positives = positives['train'].select(range(len(negatives['train'])))\n",
    "\n",
    "print(short_positives)\n",
    "\n",
    "downsized_dataset = concatenate_datasets([short_positives, negatives['train']])\n",
    "\n",
    "print(downsized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-9ab259d81c7af6d1.arrow\n",
      "Loading cached split indices for dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-422398295eb4d128.arrow and C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-3283e3e9f0e377e4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 1087\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 121\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def replace_values(example):\n",
    "    # Replace values in the label column\n",
    "    if \"label\" in example:\n",
    "        example[\"label\"] = 1 if example[\"label\"] == 2 else example[\"label\"]\n",
    "    return example\n",
    "\n",
    "# Use the map function to apply the custom mapping\n",
    "downsized_dataset = downsized_dataset.map(replace_values)\n",
    "downsized_dataset = downsized_dataset.train_test_split(test_size=0.1, shuffle=True)\n",
    "print(downsized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-501ca8eafc8dc863.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-d70d30e07659248a.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = downsized_dataset['train'].map(tokenize_function, batched=True)\n",
    "tokenized_datasets_eval = downsized_dataset['test'].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57411688\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
    "\n",
    "model = model.to(0)\n",
    "\n",
    "print(model.get_memory_footprint())\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", per_device_train_batch_size=128, per_device_eval_batch_size=128, num_train_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8/18 [00:11<00:03,  2.62it/s]\n",
      " 56%|█████▌    | 10/18 [00:11<00:02,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6024297475814819, 'eval_accuracy': 0.9504132231404959, 'eval_runtime': 0.076, 'eval_samples_per_second': 1592.026, 'eval_steps_per_second': 13.157, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:12<00:00,  9.50it/s]\n",
      "100%|██████████| 18/18 [00:12<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5375222563743591, 'eval_accuracy': 0.9834710743801653, 'eval_runtime': 0.073, 'eval_samples_per_second': 1657.53, 'eval_steps_per_second': 13.699, 'epoch': 2.0}\n",
      "{'train_runtime': 12.5171, 'train_samples_per_second': 173.683, 'train_steps_per_second': 1.438, 'train_loss': 0.6289352311028374, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=0.6289352311028374, metrics={'train_runtime': 12.5171, 'train_samples_per_second': 173.683, 'train_steps_per_second': 1.438, 'train_loss': 0.6289352311028374, 'epoch': 2.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Gusso/.cache/huggingface/datasets/zeroshot___csv/zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 2/2 [00:00<00:00, 400.24it/s]\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b2d98c45395bc49c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-98a6e9e55fa382e5.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-67576bd48af9ed0f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-34cfe024d4a4d1dc.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 4846\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = load_dataset('zeroshot/twitter-financial-news-sentiment')\n",
    "\n",
    "def filter_function(example):\n",
    "    return example[\"label\"] != 2\n",
    "\n",
    "# Use the filter method to remove records\n",
    "filtered_dataset = validation_dataset.filter(filter_function)\n",
    "\n",
    "def tokenize_function2(examples):\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets_validation = filtered_dataset.map(tokenize_function2, batched=True)\n",
    "\n",
    "# Print the modified dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "model = BetterTransformer.transform(model)\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 20.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.608889639377594,\n",
       " 'eval_accuracy': 0.7944038929440389,\n",
       " 'eval_runtime': 0.4505,\n",
       " 'eval_samples_per_second': 1824.573,\n",
       " 'eval_steps_per_second': 15.538}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate(eval_dataset=tokenized_datasets_validation['validation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging_torch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

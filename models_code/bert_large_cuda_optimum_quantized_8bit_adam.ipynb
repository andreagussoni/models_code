{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from optimum.bettertransformer import BetterTransformer\n",
    "import torch\n",
    "from pynvml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1\n",
      "Is CUDA enabled? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (C:/Users/Gusso/.cache/huggingface/datasets/financial_phrasebank/sentences_50agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.44it/s]\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-4069f8bdc2072a81.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-255302c37e6b94c9.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-913aca77f5bc0114.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 604\n",
      "})\n",
      "Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 1208\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"financial_phrasebank\", 'sentences_50agree')\n",
    "\n",
    "neutrals = dataset.filter(lambda example: example[\"label\"] == 1)\n",
    "positives = dataset.filter(lambda example: example[\"label\"] == 2)\n",
    "negatives = dataset.filter(lambda example: example[\"label\"] == 0)\n",
    "\n",
    "short_positives = positives['train'].select(range(len(negatives['train'])))\n",
    "\n",
    "print(short_positives)\n",
    "\n",
    "downsized_dataset = concatenate_datasets([short_positives, negatives['train']])\n",
    "\n",
    "print(downsized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141\\cache-9ab259d81c7af6d1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 1087\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 121\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def replace_values(example):\n",
    "    # Replace values in the label column\n",
    "    if \"label\" in example:\n",
    "        example[\"label\"] = 1 if example[\"label\"] == 2 else example[\"label\"]\n",
    "    return example\n",
    "\n",
    "# Use the map function to apply the custom mapping\n",
    "downsized_dataset = downsized_dataset.map(replace_values)\n",
    "downsized_dataset = downsized_dataset.train_test_split(test_size=0.1, shuffle=True)\n",
    "print(downsized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_datasets = downsized_dataset['train'].map(tokenize_function, batched=True)\n",
    "tokenized_datasets_eval = downsized_dataset['test'].map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin c:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll\n",
      "CUDA SETUP: CUDA runtime path found: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.7\\bin\\cudart64_110.dll\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary c:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: C:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2 did not contain ['cudart64_110.dll', 'cudart64_120.dll'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "c:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:152: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('C:/Users/Gusso/anaconda3/envs/hugging_torch_2/Library/usr/bin'), WindowsPath('C:/ProgramData/DockerDesktop/version-bin'), WindowsPath('C:/Users/Gusso/anaconda3/envs/hugging_torch_2/Library/mingw-w64/bin'), WindowsPath('C:/Users/Gusso/anaconda3/Library/usr/bin')}\n",
      "  warn(msg)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367257604\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-large-uncased\", load_in_8bit=True)\n",
    "\n",
    "# model = model.to(0)\n",
    "\n",
    "print(model.get_memory_footprint())\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/408 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 33%|███▎      | 136/408 [01:31<02:41,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_accuracy': 0.4628099173553719, 'eval_runtime': 4.574, 'eval_samples_per_second': 26.454, 'eval_steps_per_second': 3.498, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 67%|██████▋   | 272/408 [03:00<01:19,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_accuracy': 0.4628099173553719, 'eval_runtime': 4.5825, 'eval_samples_per_second': 26.405, 'eval_steps_per_second': 3.492, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 408/408 [04:28<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_accuracy': 0.4628099173553719, 'eval_runtime': 4.4955, 'eval_samples_per_second': 26.916, 'eval_steps_per_second': 3.559, 'epoch': 3.0}\n",
      "{'train_runtime': 268.615, 'train_samples_per_second': 12.14, 'train_steps_per_second': 1.519, 'train_loss': 0.3140001483992034, 'epoch': 3.0}\n",
      "Time: 268.62\n",
      "Samples/second: 12.14\n"
     ]
    },
    {
     "ename": "NVMLError_LibraryNotFound",
     "evalue": "NVML Shared Library Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\pynvml.py:641\u001b[0m, in \u001b[0;36m_LoadNvmlLibrary\u001b[1;34m()\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (sys\u001b[38;5;241m.\u001b[39mplatform[:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;66;03m# cdecl calling convention\u001b[39;00m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;66;03m# load nvml.dll from %ProgramFiles%/NVIDIA Corporation/NVSMI/nvml.dll\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m     nvmlLib \u001b[38;5;241m=\u001b[39m \u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProgramFiles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Program Files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNVIDIA Corporation/NVSMI/nvml.dll\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;66;03m# assume linux\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\ctypes\\__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find module 'C:\\Program Files\\NVIDIA Corporation\\NVSMI\\nvml.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNVMLError_LibraryNotFound\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mprint_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mprint_summary\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_runtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSamples/second: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_samples_per_second\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mprint_gpu_utilization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mprint_gpu_utilization\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_gpu_utilization\u001b[39m():\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mnvmlInit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     handle \u001b[38;5;241m=\u001b[39m nvmlDeviceGetHandleByIndex(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m     info \u001b[38;5;241m=\u001b[39m nvmlDeviceGetMemoryInfo(handle)\n",
      "File \u001b[1;32mc:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\pynvml.py:608\u001b[0m, in \u001b[0;36mnvmlInit\u001b[1;34m()\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnvmlInit\u001b[39m():\n\u001b[1;32m--> 608\u001b[0m     \u001b[43m_LoadNvmlLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;66;03m# Initialize the library\u001b[39;00m\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    613\u001b[0m     fn \u001b[38;5;241m=\u001b[39m _nvmlGetFunctionPointer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvmlInit_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\pynvml.py:646\u001b[0m, in \u001b[0;36m_LoadNvmlLibrary\u001b[1;34m()\u001b[0m\n\u001b[0;32m    644\u001b[0m         nvmlLib \u001b[38;5;241m=\u001b[39m CDLL(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibnvidia-ml.so.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ose:\n\u001b[1;32m--> 646\u001b[0m     \u001b[43m_nvmlCheckReturn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNVML_ERROR_LIBRARY_NOT_FOUND\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (nvmlLib \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    648\u001b[0m     _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)\n",
      "File \u001b[1;32mc:\\Users\\Gusso\\anaconda3\\envs\\hugging_torch_2\\lib\\site-packages\\pynvml.py:310\u001b[0m, in \u001b[0;36m_nvmlCheckReturn\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_nvmlCheckReturn\u001b[39m(ret):\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (ret \u001b[38;5;241m!=\u001b[39m NVML_SUCCESS):\n\u001b[1;32m--> 310\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NVMLError(ret)\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mNVMLError_LibraryNotFound\u001b[0m: NVML Shared Library Not Found"
     ]
    }
   ],
   "source": [
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model = BetterTransformer.transform(model)\n",
    "\n",
    "trainer2 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Gusso/.cache/huggingface/datasets/zeroshot___csv/zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 2/2 [00:00<00:00, 84.82it/s]\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b2d98c45395bc49c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-98a6e9e55fa382e5.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-fe9caa88d8fabe99.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Gusso\\.cache\\huggingface\\datasets\\zeroshot___csv\\zeroshot--twitter-financial-news-sentiment-ccca0f3c622c5b67\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-9fbf952eb2a40f9a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 4846\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = load_dataset('zeroshot/twitter-financial-news-sentiment')\n",
    "\n",
    "def filter_function(example):\n",
    "    return example[\"label\"] != 2\n",
    "\n",
    "# Use the filter method to remove records\n",
    "filtered_dataset = validation_dataset.filter(filter_function)\n",
    "\n",
    "def tokenize_function2(examples):\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_datasets_validation = filtered_dataset.map(tokenize_function2, batched=True)\n",
    "\n",
    "# Print the modified dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:52<00:00,  7.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': nan,\n",
       " 'eval_accuracy': 0.4221411192214112,\n",
       " 'eval_runtime': 52.7567,\n",
       " 'eval_samples_per_second': 15.581,\n",
       " 'eval_steps_per_second': 7.79}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.evaluate(eval_dataset=tokenized_datasets_validation['validation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging_torch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
